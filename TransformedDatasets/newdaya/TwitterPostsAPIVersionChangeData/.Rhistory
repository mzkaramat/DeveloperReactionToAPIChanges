install.packages('h2o')
library(h2o)
h2o.init()
# Import a sample binary outcome train/test set into H2O
train <- h2o.importFile("https://s3.amazonaws.com/erin-data/higgs/higgs_train_10k.csv")
test <- h2o.importFile("https://s3.amazonaws.com/erin-data/higgs/higgs_test_5k.csv")
class(train)
head(train)
dim(train)
# Identify predictors and response
y <- "response"
x <- setdiff(names(train), y)
# For binary classification, response should be a factor
train[,y] <- as.factor(train[,y])
test[,y] <- as.factor(test[,y])
aml <- h2o.automl(x = x, y = y,
training_frame = train,
max_runtime_secs = 30)
# View the AutoML Leaderboard
lb <- aml@leaderboard
lb
# The leader model is stored here
aml@leader
pred <- h2o.predict(aml, test)  # predict(aml, test) also works
# or:
pred <- h2o.predict(aml@leader, test)
class(pred)
head(pred)
#training the automl algorithm
aml <- h2o.automl(x = x, y = y,
training_frame = train,
max_runtime_secs = 300)
# View the AutoML Leaderboard
lb <- aml@leaderboard
lb
# The leader model is stored here
aml@leader
#training the automl algorithm
aml <- h2o.automl(x = x, y = y,
training_frame = train,
max_runtime_secs = 1000)
#training the automl algorithm
aml <- h2o.automl(x = x, y = y,
training_frame = train,
max_runtime_secs = 10000)
#training the automl algorithm
aml <- h2o.automl(x = x, y = y,
training_frame = train,
max_runtime_secs = 100)
# View the AutoML Leaderboard
lb <- aml@leaderboard
lb
# The leader model is stored here
aml@leader
library(h2o)
h2o.init()
h2o.no_progress()  # Turn off progress bars for notebook readability
docker_data_path <- "/home/h2o/data/automl/powerplant_output.csv"
if (file.exists(docker_data_path)) {
data_path <- docker_data_path
} else {
data_path <- "https://github.com/h2oai/h2o-tutorials/raw/master/h2o-world-2017/automl/data/powerplant_output.csv"
}
# Load data into H2O
df <- h2o.importFile(data_path)
class(df)
head(df)
h2o.describe(df)
y <- "HourlyEnergyOutputMW"
splits <- h2o.splitFrame(df, ratios = 0.8, seed = 1)
train <- splits[[1]]
test <- splits[[2]]
aml <- h2o.automl(y = y,
training_frame = train,
leaderboard_frame = test,
max_runtime_secs = 60,
seed = 1,
project_name = "powerplant_lb_frame")
aml2 <- h2o.automl(y = y,
training_frame = df,
max_runtime_secs = 60,
seed = 1,
project_name = "powerplant_full_data")
print(aml@leaderboard)
print(aml2@leaderboard)
pred <- h2o.predict(aml, test)  # predict(aml, test) and h2o.predict(aml@leader, test) also work
head(pred)
perf <- h2o.performance(aml@leader, test)
perf
# Install packages
install.packages("timetk")
install.packages("tidyquant")
# Load libraries
library(h2o)        # Awesome ML Library
library(timetk)     # Toolkit for working with time series in R
library(tidyquant)  # Loads tidyverse, financial pkgs, used to get data
# Beer, Wine, Distilled Alcoholic Beverages, in Millions USD
beer_sales_tbl <- tq_get("S4248SM144NCEN", get = "economic.data", from = "2010-01-01", to = "2017-10-27")
beer_sales_tbl
dim(beer_sales_tbl)
head(beer_sales_tbl)
# Plot Beer Sales with train, validation, and test sets shown
beer_sales_tbl %>%
ggplot(aes(date, price)) +
# Train Region
annotate("text", x = ymd("2012-01-01"), y = 7000,
color = palette_light()[[1]], label = "Train Region") +
# Validation Region
geom_rect(xmin = as.numeric(ymd("2016-01-01")),
xmax = as.numeric(ymd("2016-12-31")),
ymin = 0, ymax = Inf, alpha = 0.02,
fill = palette_light()[[3]]) +
annotate("text", x = ymd("2016-07-01"), y = 7000,
color = palette_light()[[1]], label = "Validation\nRegion") +
# Test Region
geom_rect(xmin = as.numeric(ymd("2017-01-01")),
xmax = as.numeric(ymd("2017-08-31")),
ymin = 0, ymax = Inf, alpha = 0.02,
fill = palette_light()[[4]]) +
annotate("text", x = ymd("2017-05-01"), y = 7000,
color = palette_light()[[1]], label = "Test\nRegion") +
# Data
geom_line(col = palette_light()[1]) +
geom_point(col = palette_light()[1]) +
geom_ma(ma_fun = SMA, n = 12, size = 1) +
# Aesthetics
theme_tq() +
scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
labs(title = "Beer Sales: 2007 through 2017",
subtitle = "Train, Validation, and Test Sets Shown")
# Starting point
beer_sales_tbl %>% glimpse()
beer_sales_tbl_aug %>% glimpse()
# Augment (adds data frame columns)
beer_sales_tbl_aug <- beer_sales_tbl %>%
tk_augment_timeseries_signature()
beer_sales_tbl_aug %>% glimpse()
head(beer_sales_tbl_aug)
dim(beer_sales_tbl_aug)
head(beer_sales_tbl_aug)
colnames(beer_sales_tbl_aug)
class(beer_sales_tbl_aug$date)
beer_sales_tbl_aug %>%
select_if(~ !is.Date(.))
beer_sales_tbl_aug
beer_sales_tbl_aug %>%
select_if(~ !is.Date(.)) %>%
select_if(~ !any(is.na(.)))
beer_sales_tbl_aug %>%
select_if(~ !is.Date(.)) %>%
select_if(~ !any(is.na(.))) %>%dim()
beer_sales_tbl_aug %>%
select_if(~ !is.Date(.)) %>%dim()
beer_sales_tbl_aug %>%
select_if(~ !is.Date(.)) %>%
select_if(~ !any(is.na(.))) %>%
mutate_if(is.ordered, ~ as.character(.) %>% as.factor)
beer_sales_tbl_clean %>% glimpse()
beer_sales_tbl_clean <- beer_sales_tbl_aug %>%
select_if(~ !is.Date(.)) %>%
select_if(~ !any(is.na(.))) %>%
mutate_if(is.ordered, ~ as.character(.) %>% as.factor)
beer_sales_tbl_clean %>% glimpse()
# Split into training, validation and test sets
train_tbl <- beer_sales_tbl_clean %>% filter(year < 2016)
valid_tbl <- beer_sales_tbl_clean %>% filter(year == 2016)
test_tbl  <- beer_sales_tbl_clean %>% filter(year == 2017)
h2o.init()        # Fire up h2o
h2o.no_progress() # Turn off progress bars
# Convert to H2OFrame objects
train_h2o <- as.h2o(train_tbl)
valid_h2o <- as.h2o(valid_tbl)
test_h2o  <- as.h2o(test_tbl)
x <- setdiff(names(train_h2o), y)
# Set names for h2o
y <- "price"
x <- setdiff(names(train_h2o), y)
# linear regression model used, but can use any model
automl_models_h2o <- h2o.automl(
x = x,
y = y,
training_frame = train_h2o,
validation_frame = valid_h2o,
leaderboard_frame = test_h2o,
max_runtime_secs = 60,
stopping_metric = "deviance")
# Extract leader model
automl_leader <- automl_models_h2o@leader
pred_h2o <- h2o.predict(automl_leader, newdata = test_h2o)
h2o.performance(automl_leader, newdata = test_h2o)
# Investigate test error
error_tbl <- beer_sales_tbl %>%
filter(lubridate::year(date) == 2017) %>%
add_column(pred = pred_h2o %>% as.tibble() %>% pull(predict)) %>%
rename(actual = price) %>%
mutate(
error     = actual - pred,
error_pct = error / actual
)
error_tbl
error_tbl %>%
summarise(
me   = mean(error),
rmse = mean(error^2)^0.5,
mae  = mean(abs(error)),
mape = mean(abs(error_pct)),
mpe  = mean(error_pct)
) %>%
glimpse()
# Libraries needed for bonus material
library(extrafont) # More fonts!! We'll use Chiller
install.packages('extrafont')
# Libraries needed for bonus material
library(extrafont) # More fonts!! We'll use Chiller
# Loads Chiller and a bunch of system fonts
# Note - Your fontset may differ if you are using Mac / Linux
loadfonts(device="win")
# Create spooky dark theme:
theme_spooky = function(base_size = 10, base_family = "Chiller") {
theme_grey(base_size = base_size, base_family = base_family) %+replace%
theme(
# Specify axis options
axis.line = element_blank(),
axis.text.x = element_text(size = base_size*0.8, color = "white", lineheight = 0.9),
axis.text.y = element_text(size = base_size*0.8, color = "white", lineheight = 0.9),
axis.ticks = element_line(color = "white", size  =  0.2),
axis.title.x = element_text(size = base_size, color = "white", margin = margin(0, 10, 0, 0)),
axis.title.y = element_text(size = base_size, color = "white", angle = 90, margin = margin(0, 10, 0, 0)),
axis.ticks.length = unit(0.3, "lines"),
# Specify legend options
legend.background = element_rect(color = NA, fill = " gray10"),
legend.key = element_rect(color = "white",  fill = " gray10"),
legend.key.size = unit(1.2, "lines"),
legend.key.height = NULL,
legend.key.width = NULL,
legend.text = element_text(size = base_size*0.8, color = "white"),
legend.title = element_text(size = base_size*0.8, face = "bold", hjust = 0, color = "white"),
legend.position = "none",
legend.text.align = NULL,
legend.title.align = NULL,
legend.direction = "vertical",
legend.box = NULL,
# Specify panel options
panel.background = element_rect(fill = " gray10", color  =  NA),
#panel.border = element_rect(fill = NA, color = "white"),
panel.border = element_blank(),
panel.grid.major = element_line(color = "grey35"),
panel.grid.minor = element_line(color = "grey20"),
panel.spacing = unit(0.5, "lines"),
# Specify facetting options
strip.background = element_rect(fill = "grey30", color = "grey10"),
strip.text.x = element_text(size = base_size*0.8, color = "white"),
strip.text.y = element_text(size = base_size*0.8, color = "white",angle = -90),
# Specify plot options
plot.background = element_rect(color = " gray10", fill = " gray10"),
plot.title = element_text(size = base_size*1.2, color = "white",hjust=0,lineheight=1.25,
margin=margin(2,2,2,2)),
plot.subtitle = element_text(size = base_size*1, color = "white",hjust=0,  margin=margin(2,2,2,2)),
plot.caption = element_text(size = base_size*0.8, color = "white",hjust=0),
plot.margin = unit(rep(1, 4), "lines")
)
}
beer_sales_tbl %>%
ggplot(aes(x = date, y = price)) +
# Data - Spooky Orange
geom_point(size = 2, color = "gray", alpha = 0.5, shape = 21, fill = "orange") +
geom_line(color = "orange", size = 0.5) +
geom_ma(n = 12, color = "white") +
# Predictions - Spooky Purple
geom_point(aes(y = pred), size = 2, color = "gray", alpha = 1, shape = 21, fill = "purple", data = error_tbl) +
geom_line(aes(y = pred), color = "purple", size = 0.5, data = error_tbl) +
# Aesthetics
theme_spooky(base_size = 20) +
labs(
title = "Beer Sales Forecast: h2o + timetk",
subtitle = "H2O had highest accuracy, MAPE = 3.9%",
caption = "Thanks to @lenkiefer for theme_spooky!"
)
class(test_h2o)
dim(test_h2o)
head(test_h2o)
iris
head(iris)
download.packages("gower",　destdir="C:\tmp")
download.packages("gower",　destdir="C:\tmp")
download.packages("gower",　destdir="C:\tmp")
download.packages("gower",　destdir="C:\\tmp")
shiny::runApp('D:/hackathon/app/SmartScheduler')
library(data.table)
library(reshape)
library(dplyr)
library(ggplot2)
library(gridExtra )
master_df <- fread('customer_filter.csv')
install.packages('data.table')
install.packages('reshape')
install.packages('dplyr')
install.packages('ggplot2')
install.packages('gridExtra')
library(data.table)
library(reshape)
library(dplyr)
library(ggplot2)
library(gridExtra )
library(dplyr)
library(dplyr)
library(dplyr)
library(dplyr)
library(dplyr)
install.packages('dplyr')
librayr(dplyr)
library(dplyr)
library(dplur)
library(dplyr)
library(dplyr)
install.packages('dplyr')
library(dplyr)
library(dplyr)
library(plyr)
install.packages("dplyr")
library(dplyrr)
library(dplyr)
install.packages('reshape')
library(reshape)
library(data.table)
library(reshape)
library(dplyr)
library(ggplot2)
library(gridExtra )
hist(rnorm(50))
setwd("D:\\temp")
library(data.table)
data <- fread('DimAssetV1.csv')
head(data)
length(unique(data$SerialNumber))
length(unique(data$EquipmentNickName))
library(data.table)
library(dplyr)
library(reshape)
setwd('D:\\DeveloperAPIopinionMining\\data\\newdaya\\TwitterPostsAPIVersionChangeData')
data <- fread('transformed_tweets_data.csv')
data%>%
mutate(add_param = grepl('add*param',  text,ignore.case=TRUE),
del_param = grepl('del*param',  text,ignore.case=TRUE),
chn_param = grepl('add*param',  text,ignore.case=TRUE),
add_method = grepl('add*method',text,ignore.case=TRUE),
del_method = grepl('del*method',text,ignore.case=TRUE),
chn_method = grepl('add*method',text,ignore.case=TRUE),
)%>%
group_by(ver)%>%
summarise(
add_param =   sum(add_param ),
del_param = sum(del_param ),
chn_param = sum(chn_param ),
add_method =sum(add_method),
del_method =sum(del_method),
chn_method =sum(chn_method)
)
twit_result = data%>%
mutate(add_param = grepl('add*param',  text,ignore.case=TRUE),
del_param = grepl('del*param',  text,ignore.case=TRUE),
chn_param = grepl('add*param',  text,ignore.case=TRUE),
add_method = grepl('add*method',text,ignore.case=TRUE),
del_method = grepl('del*method',text,ignore.case=TRUE),
chn_method = grepl('add*method',text,ignore.case=TRUE),
)%>%
group_by(ver)%>%
summarise(
add_param =   sum(add_param ),
del_param = sum(del_param ),
chn_param = sum(chn_param ),
add_method =sum(add_method),
del_method =sum(del_method),
chn_method =sum(chn_method)
)
twit_result_trn = melt(twit_result, id=c("ver"))
ggplot(data=twit_result_trn, aes(x=ver, y=value, fill=variable)) +
geom_bar(stat="identity", position=position_dodge())+
scale_fill_brewer(palette="Paired")+
theme_minimal()
library(ggplot2)
setwd('D:\\DeveloperAPIopinionMining\\data\\newdaya\\TwitterPostsAPIVersionChangeData')
data <- fread('transformed_tweets_data.csv')
data%>%
mutate(add_param = grepl('add*param',  text,ignore.case=TRUE),
del_param = grepl('del*param',  text,ignore.case=TRUE),
chn_param = grepl('add*param',  text,ignore.case=TRUE),
add_method = grepl('add*method',text,ignore.case=TRUE),
del_method = grepl('del*method',text,ignore.case=TRUE),
chn_method = grepl('add*method',text,ignore.case=TRUE),
)%>%
group_by(ver)%>%
summarise(
add_param =   sum(add_param ),
del_param = sum(del_param ),
chn_param = sum(chn_param ),
add_method =sum(add_method),
del_method =sum(del_method),
chn_method =sum(chn_method)
)
twit_result = data%>%
mutate(add_param = grepl('add*param',  text,ignore.case=TRUE),
del_param = grepl('del*param',  text,ignore.case=TRUE),
chn_param = grepl('add*param',  text,ignore.case=TRUE),
add_method = grepl('add*method',text,ignore.case=TRUE),
del_method = grepl('del*method',text,ignore.case=TRUE),
chn_method = grepl('add*method',text,ignore.case=TRUE),
)%>%
group_by(ver)%>%
summarise(
add_param =   sum(add_param ),
del_param = sum(del_param ),
chn_param = sum(chn_param ),
add_method =sum(add_method),
del_method =sum(del_method),
chn_method =sum(chn_method)
)
twit_result_trn = melt(twit_result, id=c("ver"))
ggplot(data=twit_result_trn, aes(x=ver, y=value, fill=variable)) +
geom_bar(stat="identity", position=position_dodge())+
scale_fill_brewer(palette="Paired")+
theme_minimal()
setwd('D:\\DeveloperAPIopinionMining\\data\\newdaya\\aspnet_transformed_data')
data <- fread('aspnet_transformed_data.csv')
head(data)
dim(data)
aspnet_result = data%>%
mutate(add_param = grepl('add*param',  text,ignore.case=TRUE),
del_param = grepl('del*param',  text,ignore.case=TRUE),
chn_param = grepl('add*param',  text,ignore.case=TRUE),
add_method = grepl('add*method',text,ignore.case=TRUE),
del_method = grepl('del*method',text,ignore.case=TRUE),
chn_method = grepl('add*method',text,ignore.case=TRUE),
)%>%
group_by(ver)%>%
summarise(
add_param =   sum(add_param ),
del_param = sum(del_param ),
chn_param = sum(chn_param ),
add_method =sum(add_method),
del_method =sum(del_method),
chn_method =sum(chn_method)
)
aspnet_result_trn = melt(aspnet_result, id=c("ver"))
ggplot(data=aspnet_result_trn, aes(x=ver, y=value, fill=variable)) +
geom_bar(stat="identity", position=position_dodge())+
scale_fill_brewer(palette="Paired")+
theme_minimal()
head(aspnet_result)
aspnet_result_trn
aspnet_result_trn = melt(aspnet_result, id=c("ver"))
library(reshape2)
aspnet_result_trn = melt(aspnet_result, id=c("ver"))
ggplot(data=aspnet_result_trn, aes(x=ver, y=value, fill=variable)) +
geom_bar(stat="identity", position=position_dodge())+
scale_fill_brewer(palette="Paired")+
theme_minimal()
head(aspnet_result)
dim(aspnet_result)
dim(data)
colnames(data)
head(data)
head(data,1)
setwd('D:\\DeveloperAPIopinionMining\\data\\newdaya\\TwitterPostsAPIVersionChangeData')
data <- fread('transformed_tweets_data.csv')
data%>%
mutate(add_param = grepl('add*param',  text,ignore.case=TRUE),
del_param = grepl('del*param',  text,ignore.case=TRUE),
chn_param = grepl('add*param',  text,ignore.case=TRUE),
add_method = grepl('add*method',text,ignore.case=TRUE),
del_method = grepl('del*method',text,ignore.case=TRUE),
chn_method = grepl('add*method',text,ignore.case=TRUE),
)%>%
group_by(ver)%>%
summarise(
add_param =   sum(add_param ),
del_param = sum(del_param ),
chn_param = sum(chn_param ),
add_method =sum(add_method),
del_method =sum(del_method),
chn_method =sum(chn_method)
)
twit_result = data%>%
mutate(add_param = grepl('add*param',  text,ignore.case=TRUE),
del_param = grepl('del*param',  text,ignore.case=TRUE),
chn_param = grepl('add*param',  text,ignore.case=TRUE),
add_method = grepl('add*method',text,ignore.case=TRUE),
del_method = grepl('del*method',text,ignore.case=TRUE),
chn_method = grepl('add*method',text,ignore.case=TRUE),
)%>%
group_by(ver)%>%
summarise(
add_param =   sum(add_param ),
del_param = sum(del_param ),
chn_param = sum(chn_param ),
add_method =sum(add_method),
del_method =sum(del_method),
chn_method =sum(chn_method)
)
twit_result_trn = melt(twit_result, id=c("ver"))
ggplot(data=twit_result_trn, aes(x=ver, y=value, fill=variable)) +
geom_bar(stat="identity", position=position_dodge())+
scale_fill_brewer(palette="Paired")+
theme_minimal()
shiny::runApp('D:/DeveloperAPIopinionMining/TextMining')
runApp('D:/DeveloperAPIopinionMining/TextMining')
if(!require('data.table')){ install.packages('data.table', repos='http://cran.us.r-project.org' ,lib=.libPaths()) }
if(!require('dplyr')){ install.packages('dplyr', repos='http://cran.us.r-project.org' ,lib=.libPaths()) }
if(!require('reshape2')){ install.packages('reshape2', repos='http://cran.us.r-project.org' ,lib=.libPaths()) }
if(!require('reshape')){ install.packages('reshape', repos='http://cran.us.r-project.org' ,lib=.libPaths()) }
if(!require('gridExtra')){ install.packages('gridExtra', repos='http://cran.us.r-project.org' ,lib=.libPaths()) }
if(!require('grid')){ install.packages('grid', repos='http://cran.us.r-project.org' ,lib=.libPaths()) }
