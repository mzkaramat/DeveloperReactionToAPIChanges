{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\mk73680\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mk73680\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mk73680\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "from IPython import display\n",
    "import math\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "sns.set(style='darkgrid', context='talk', palette='Dark2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   antwort_id                                              Title  \\\n",
      "0     8273117                                                NaN   \n",
      "1    33446954  Angular JSON Display Single Result without Ng-...   \n",
      "2    25183554                                                NaN   \n",
      "3    25194037                                                NaN   \n",
      "4    16695595                        Twitter iOS 6 oauth or not?   \n",
      "\n",
      "                                                Body  Score  \\\n",
      "0  <p>You would have to custom code the second pa...      1   \n",
      "1  <p>I'm still develop app for show news update ...      0   \n",
      "2  <p>To get the user's information from Twitter,...      2   \n",
      "3  <p>The Play JSON framework has <a href=\"http:/...      4   \n",
      "4  <p>Am i correct in saying that you do not need...      0   \n",
      "\n",
      "          CreationDate    parentid  Post Link  \n",
      "0  2011-11-25 18:42:22   8268229.0    8273117  \n",
      "1  2015-10-31 01:01:22         NaN   33446954  \n",
      "2  2014-08-07 13:14:55  25178919.0   25183554  \n",
      "3  2014-08-07 23:47:45  25193016.0   25194037  \n",
      "4  2013-05-22 15:18:24         NaN   16695595  \n",
      "<p>You would have to custom code the second part.</p>\n",
      "\n",
      "<ol>\n",
      "<li><p>Use <a href=\"https://dev.twitter.com/docs/api/1/get/statuses/user_timeline\" rel=\"nofollow\">https://dev.twitter.com/docs/api/1/get/statuses/user_timeline</a> - to get the latest tweets from a specific user.</p></li>\n",
      "<li><p>Write Code to search within the response Object of (1) with the hashtag (search-key).</p></li>\n",
      "</ol>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "pprint(df.head())\n",
    "print(df.iloc[0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SIA()\n",
    "results = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    pol_score = sia.polarity_scores(df.iloc[index,2])\n",
    "    pol_score['headline'] = df.iloc[index,2]\n",
    "    results.append(pol_score)\n",
    "    \n",
    "pprint(results[:3], width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(results)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using threshold of -0.2 and 0.2 for labelling data either as positive or negative\n",
    "df['label'] = 0\n",
    "df.loc[df['compound'] > 0.2, 'label'] = 1\n",
    "df.loc[df['compound'] < -0.2, 'label'] = -1\n",
    "df.head()\n",
    "\n",
    "print(\"Positive headlines:\\n\")\n",
    "pprint(list(df[df['label'] == 1].headline)[:5], width=200)\n",
    "\n",
    "print(\"\\nNegative headlines:\\n\")\n",
    "pprint(list(df[df['label'] == -1].headline)[:5], width=200)\n",
    "\n",
    "print(df.label.value_counts())\n",
    "print(df.label.value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "counts = df.label.value_counts(normalize=True) * 100\n",
    "\n",
    "sns.barplot(x=counts.index, y=counts, ax=ax)\n",
    "\n",
    "ax.set_xticklabels(['Negative', 'Neutral', 'Positive'])\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "print(stop_words[:20])\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokenizer.tokenize(example)\n",
    "    \n",
    "def process_text(headlines):\n",
    "    tokens = []\n",
    "    for line in headlines:\n",
    "        toks = tokenizer.tokenize(line)\n",
    "        toks = [t.lower() for t in toks if t.lower() not in stop_words]\n",
    "        tokens.extend(toks)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Positive words from labelled datasets\n",
    "pos_lines = list(df[df.label == 1].headline)\n",
    "\n",
    "pos_tokens = process_text(pos_lines)\n",
    "pos_freq = nltk.FreqDist(pos_tokens)\n",
    "\n",
    "pos_freq.most_common(20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequency distribution of positive words, it follows powerlaw distribution\n",
    "y_val = [x[1] for x in pos_freq.most_common()]\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.plot(y_val)\n",
    "\n",
    "plt.xlabel(\"Words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Word Frequency Distribution (Positive)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot of log which confirms that less words occupied more space\n",
    "y_final = []\n",
    "for i, k, z, t in zip(y_val[0::4], y_val[1::4], y_val[2::4], y_val[3::4]):\n",
    "    y_final.append(math.log(i + k + z + t))\n",
    "\n",
    "x_val = [math.log(i + 1) for i in range(len(y_final))]\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.xlabel(\"Words (Log)\")\n",
    "plt.ylabel(\"Frequency (Log)\")\n",
    "plt.title(\"Word Frequency Distribution (Positive)\")\n",
    "plt.plot(x_val, y_final)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeating same steps for negative words\n",
    "neg_lines = list(df[df.label == -1].headline)\n",
    "\n",
    "neg_tokens = process_text(neg_lines)\n",
    "neg_freq = nltk.FreqDist(neg_tokens)\n",
    "\n",
    "neg_freq.most_common(20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = [x[1] for x in neg_freq.most_common()]\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.plot(y_val)\n",
    "\n",
    "plt.xlabel(\"Words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Word Frequency Distribution (Negative)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final = []\n",
    "for i, k, z in zip(y_val[0::3], y_val[1::3], y_val[2::3]):\n",
    "    if i + k + z == 0:\n",
    "        break\n",
    "    y_final.append(math.log(i + k + z))\n",
    "\n",
    "x_val = [math.log(i+1) for i in range(len(y_final))]\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.xlabel(\"Words (Log)\")\n",
    "plt.ylabel(\"Frequency (Log)\")\n",
    "plt.title(\"Word Frequency Distribution (Negative)\")\n",
    "plt.plot(x_val, y_final)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
